{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YLG-Ung2Tzu",
        "outputId": "2051ac03-b627-4ea0-8a19-4a81741e772c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import pandas as pd\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "\n",
        "data = pd.read_csv('final_selected_features.csv', header=0)\n",
        "data = data.dropna()\n",
        "print(data.shape)\n",
        "print(list(data.columns))\n",
        "del data['Unnamed: 0']\n",
        "\n",
        "X = data.drop(\"creditworthy\", axis=1)\n",
        "y = data[\"creditworthy\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "\n",
        "\n",
        "clf1 =  LogisticRegression()\n",
        "clf2 = RandomForestClassifier(random_state=RANDOM_SEED)\n",
        "clf3 = SVC(random_state=RANDOM_SEED)\n",
        "lr = LogisticRegression()\n",
        "\n",
        "\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 26)\n",
            "['Unnamed: 0', 'Credit history_delay in paying off', 'Savings account/bonds_>= 1000 DM', 'foreign worker_no', 'Age in years', 'Savings account/bonds_<100 DM', 'Purpose_business', 'Duration in month', 'Savings account/bonds_no savings account', 'Purpose_education', 'Other installment plans_bank', 'Status of existing checking account_<0 DM', 'Status of existing checking account_no checking account', 'Credit history_all credits at this bank paid back duly', 'Status of existing checking account_0 <= <200 DM', 'Purpose_car (used)', 'Present employment since_>=7 years', 'Credit history_no credits taken', 'Credit amount', 'Property_real estate', 'Purpose_car (new)', 'Purpose_radio/television', 'Property_unknown / no property', 'Other debtors / guarantors_guarantor', 'Present employment since_unemployed', 'creditworthy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml-kg05H3_jd"
      },
      "source": [
        "# Learn to predict each class against the other\n",
        "classifier = OneVsRestClassifier(sclf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaNhamyH4AVN",
        "outputId": "ac5b317d-625d-4e1d-c831-e1c31a9ba054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
        "\n",
        "print(y_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.97933471 0.02066529]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.95983592 0.04016408]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01456092 0.98543908]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.97933471 0.02066529]\n",
            " [0.98261996 0.01738004]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.98261996 0.01738004]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02846734 0.97153266]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.95983592 0.04016408]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.02397213 0.97602787]\n",
            " [0.95983592 0.04016408]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.01223399 0.98776601]\n",
            " [0.97933471 0.02066529]\n",
            " [0.97933471 0.02066529]\n",
            " [0.02397213 0.97602787]\n",
            " [0.01223399 0.98776601]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibM-uWy8yWR"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5mIVcEJ8xd0",
        "outputId": "55a603c4-d74d-4e36-8ad0-10dc48fefe3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "model = keras.Sequential([keras.layers.Flatten(input_shape (28,28)),\n",
        "                keras.layers.Dense(128,activation = tf.nn.sigmoid),\n",
        "                keras.layers.Dense(10,activation = tf.nn.softmax)])\n",
        "model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-59390458dbcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = keras.Sequential([keras.layers.Flatten(input_shape (28,28)),\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 keras.layers.Dense(10,activation = tf.nn.softmax)])\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKGsbss_C74s"
      },
      "source": [
        "MEDIUM GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKkaN27MTs7v"
      },
      "source": [
        "k = 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slx-Rb7SC7QI"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.plotting import plot_decision_regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxbxN-vlDELU"
      },
      "source": [
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC8AkSoDDI9U"
      },
      "source": [
        "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
        "clf_list = [clf1, clf2, clf3, sclf]\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "clf_cv_mean = []\n",
        "clf_cv_std = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JTeZit6DNbw",
        "outputId": "1ee98e7f-53f6-4895-a15e-a34db85b674c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "for clf, label, grd in zip(clf_list, label, grid):\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3, scoring='accuracy')\n",
        "    print (\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
        "    clf_cv_mean.append(scores.mean())\n",
        "    clf_cv_std.append(scores.std())\n",
        "    clf.fit(X, y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.60 (+/- 0.04) [KNN]\n",
            "Accuracy: 0.72 (+/- 0.01) [Random Forest]\n",
            "Accuracy: 0.70 (+/- 0.03) [Naive Bayes]\n",
            "Accuracy: 0.71 (+/- 0.01) [Stacking Classifier]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmeg8ZN5EAbQ"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX5ZBObGDTxm",
        "outputId": "22075061-4eda-48bf-b881-b4d03f9f8561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf3.fit(X_train,y_train)\n",
        "clf3.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkRFE4FAspTE"
      },
      "source": [
        "Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-5pO6LYsv7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "68446407-345d-4bdb-b2da-00800978a5e8"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.plotting import plot_decision_regions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQnnH6PEFIZ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "5caf50b4-dbb0-49fe-9a41-d9268dd2fa7d"
      },
      "source": [
        "data = pd.read_csv('german_processed.csv', header=0)\n",
        "data = data_without_fs.dropna()\n",
        "print(data_without_fs.shape)\n",
        "print(list(data_without_fs.columns))\n",
        "#del data_without_fs['Unnamed: 0']\n",
        "X = data.drop(\"creditworthy\", axis=1)\n",
        "y = data[\"creditworthy\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a930d311d7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'german_processed.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_without_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_without_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_without_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#del data_without_fs['Unnamed: 0']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'german_processed.csv' does not exist: b'german_processed.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdTUaJttYYe",
        "outputId": "5f172db0-b4a0-4bb3-9f7b-4e45a33b0fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data = pd.read_csv('final_selected_features_62.csv', header=0)\n",
        "data = data.dropna()\n",
        "print(data.shape)\n",
        "print(list(data.columns))\n",
        "del data['Unnamed: 0']\n",
        "X = data.drop(\"creditworthy\", axis=1)\n",
        "y = data[\"creditworthy\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 64)\n",
            "['Unnamed: 0', 'Personal status and sex_male:single', 'Present employment since_4<= <7 years', 'Credit history_delay in paying off', 'Duration in month', 'Installment rate in percentage of disposable income_1', 'Purpose_car (used)', 'Job_unemployed/ unskilled  - non-resident', 'Purpose_repairs', 'Credit history_critical account', 'Personal status and sex_male:married/widowed', 'Purpose_furniture/equipment', 'Telephone_yes', 'Savings account/bonds_>= 1000 DM', 'Present residence since_1', 'Number of people being liable to provide maintenance for_2', 'Telephone_none', 'Other installment plans_none', 'Purpose_radio/television', 'Number of people being liable to provide maintenance for_1', 'Status of existing checking account_>= 200 DM', 'Property_unknown / no property', 'Personal status and sex_male:divorced/separated', 'Present residence since_2', 'Savings account/bonds_no savings account', 'Other debtors / guarantors_co-applicant', 'Present residence since_3', 'Installment rate in percentage of disposable income_2', 'Present residence since_4', 'Status of existing checking account_no checking account', 'Personal status and sex_female:divorced/separated/married', 'Number of existing credits at this bank_1', 'Other installment plans_bank', 'Age in years', 'Purpose_business', 'Savings account/bonds_100 <= <500 DM', 'Job_unskilled - resident', 'Savings account/bonds_<100 DM', 'Status of existing checking account_<0 DM', 'Savings account/bonds_500 <= < 1000 DM', 'Housing_rent', 'Credit history_all credits at this bank paid back duly', 'Purpose_car (new)', 'Purpose_retraining', 'Purpose_education', 'Present employment since_>=7 years', 'foreign worker_yes', 'Property_savings agreement/life insurance', 'Credit history_no credits taken', 'Other debtors / guarantors_none', 'Property_real estate', 'Status of existing checking account_0 <= <200 DM', 'Installment rate in percentage of disposable income_3', 'Purpose_domestic appliances', 'Present employment since_unemployed', 'Other installment plans_store', 'Present employment since_<1 years', 'Number of existing credits at this bank_2', 'Job_skilled employee / official', 'foreign worker_no', 'Installment rate in percentage of disposable income_4', 'Other debtors / guarantors_guarantor', 'Credit amount', 'creditworthy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr99aTfys0kz"
      },
      "source": [
        "clf1 = SVC(kernel='linear')\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = MLPClassifier(hidden_layer_sizes=(5,2), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPbq1_WDuYVt"
      },
      "source": [
        "label = ['SVC', 'Random Forest', 'MLP', 'Stacking Classifier']\n",
        "clf_list = [clf1, clf2, clf3, sclf]\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "clf_cv_mean = []\n",
        "clf_cv_std = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuUJFhqfuzFH",
        "outputId": "85b9da0d-6cc3-4d5f-a82b-7d78f2e43f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "for clf, label, grd in zip(clf_list, label, grid):\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3, scoring='accuracy')\n",
        "    print (\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
        "    clf_cv_mean.append(scores.mean())\n",
        "    clf_cv_std.append(scores.std())\n",
        "    clf.fit(X, y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.71 (+/- 0.03) [SVC]\n",
            "Accuracy: 0.73 (+/- 0.01) [Random Forest]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.69 (+/- 0.00) [MLP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.73 (+/- 0.01) [Stacking Classifier]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}